{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import yfinance as yf\n",
    "import os\n",
    "import datetime\n",
    "import mplfinance as mpf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Selection and Description\n",
    "# Domain\tDataset\tSource\tFeatures\tWebsite / APIs\n",
    "# Energy\tGEFCom2014\tKaggle\tHourly energy consumption, temperature\thttps://www.kaggle.com/code/raimondomelis/lab-time-series-linear-regression-cnn/notebook\n",
    "# Electricity Load Diagrams 2011-2014\tUCI\tElectricity consumption data (hourly)\thttps://archive.ics.uci.edu/dataset/321/electricityloaddiagrams20112014\n",
    "# Finance\tStock Prices (AAPL, GOOGL, etc.)\tYahoo Finance\tOpen, High, Low, Close, Volume\thttps://finance.yahoo.com/quote/AAPL/history?p=AAPL / APIs (See Python code)\n",
    "# Climate\tGlobalLandTemperatures\tKaggle\tTemperature, Date\thttps://www.kaggle.com/datasets/berkeleyearth/climate-change-earth-surface-temperature-data\n",
    "# Retail\tStore Sales - Time Series Forecasting\tKaggle\tStore sales, Date, Promotions\thttps://www.kaggle.com/competitions/store-sales-time-series-forecasting\n",
    "# Transport\tBike Sharing Dataset\tUCI\tHourly bike rental counts, weather data https://archive.ics.uci.edu/dataset/275/bike+sharing+dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "def load_finance_data(ticker):\n",
    "    data = yf.download(ticker, start=\"2010-01-01\", end=\"2023-12-31\")\n",
    "    data = data[['Open', 'High', 'Low', 'Close', 'Volume']].dropna()\n",
    "    data['Returns'] = data['Close'].pct_change().fillna(0)\n",
    "    data['Ticker'] = ticker  # Add ticker column for identification\n",
    "    return data\n",
    "\n",
    "def add_time_features(df):\n",
    "    df['hour'] = df.index.hour\n",
    "    df['day'] = df.index.day\n",
    "    df['month'] = df.index.month\n",
    "    df['weekday'] = df.index.weekday\n",
    "    df['is_weekend'] = df['weekday'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "    return df\n",
    "\n",
    "# Tickers list\n",
    "stocks = ['TSLA', 'BTC-USD', 'PXE', 'JPY=X', 'ES=F', '%5EVIX']\n",
    "\n",
    "# Combined DataFrame to store all tickers' data\n",
    "combined_data = pd.DataFrame()\n",
    "\n",
    "for ticker in stocks:\n",
    "    finance_data = load_finance_data(ticker)\n",
    "    \n",
    "    # Handling Missing Values\n",
    "    # finance_data = finance_data.ffill()\n",
    "    \n",
    "    finance_data = add_time_features(finance_data)\n",
    "    scaler = MinMaxScaler()\n",
    "    if 'Close' in finance_data.columns:\n",
    "        finance_data['Close_Scaled'] = scaler.fit_transform(finance_data[['Close']])\n",
    "    \n",
    "    # Append to the combined DataFrame\n",
    "    combined_data = pd.concat([combined_data, finance_data], axis=0)\n",
    "\n",
    "# Reset index to ensure consistency after concatenation\n",
    "combined_data.reset_index(inplace=True)        \n",
    "        \n",
    "# Display the first few rows of the combined normalized data\n",
    "print(combined_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables to tune your plots\n",
    "\n",
    "# valid periods: 1d, 5d, 1mo, 3mo, 6mo, 1y, 2y, 5y, 10y, ytd, max\n",
    "period = '1d'\n",
    "\n",
    " # valid intervals: 1m, 2m, 5m, 15m, 30m, 60m, 90m, 1h, 1d, 5d, 1wk, 1mo, 3mo\n",
    "interval = '5m'\n",
    "\n",
    "# method to grab data and plot the data\n",
    "def plot_stocks_df(stocks, period='1d' , interval='1m'):\n",
    "    for stock in stocks:\n",
    "\t\t\t\t\t\t\t\t# Downloading the stock data\n",
    "\t\t\t\t\t\t\t\tplt.figure()\n",
    "\t\t\t\t\t\t\t\ttemp = yf.Ticker(stock)\n",
    "\t\t\t\t\t\t\t\thist = temp.history(period=period, interval=interval)\n",
    "\n",
    "\t\t\t\t\t\t\t\t# Converting columns to float where necessary\n",
    "\t\t\t\t\t\t\t\thist['Open'] = pd.to_numeric(hist['Open'], errors='coerce')\n",
    "\t\t\t\t\t\t\t\thist['High'] = pd.to_numeric(hist['High'], errors='coerce')\n",
    "\t\t\t\t\t\t\t\thist['Low'] = pd.to_numeric(hist['Low'], errors='coerce')\n",
    "\t\t\t\t\t\t\t\thist['Close'] = pd.to_numeric(hist['Close'], errors='coerce')\n",
    "\t\t\t\t\t\t\t\thist['Volume'] = pd.to_numeric(hist['Volume'], errors='coerce')\n",
    "\n",
    "\t\t\t\t\t\t\t\t# Plotting candlestick chart with moving averages\n",
    "\t\t\t\t\t\t\t\tmpf.plot(hist, type='candle',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tvolume=True, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tmav=(20, 5),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\ttitle=f'{stock} Candlestick Chart {datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\ttight_layout=True, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tfigratio=(10, 5))\n",
    "\n",
    "\t\t\t\t\t\t\t\t# Save the plot to a variable\n",
    "\t\t\t\t\t\t\t\tglobals()[f\"plot_{stock}_{interval}\"] = plt.gcf()\n",
    "\n",
    "\t\t\t\t\t\t\t\tplt.show()\n",
    "\n",
    "# call the method\n",
    "plot_stocks_df(stocks, period, interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Sequence length for LSTM (e.g., use the past 30 days to predict the next day)\n",
    "SEQ_LENGTH = 30\n",
    "\n",
    "# Function to create sequences for LSTM\n",
    "def create_sequences(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:(i + seq_length)])\n",
    "        y.append(data[i + seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Preparing the data for modeling\n",
    "def prepare_train_val_test(combined_data, seq_length=SEQ_LENGTH):\n",
    "    # Sort by date to maintain chronological order\n",
    "    combined_data.sort_values(by='Date', inplace=True)\n",
    "\n",
    "    # Use only the 'Close_Scaled' for prediction\n",
    "    close_prices = combined_data['Close_Scaled'].values\n",
    "\n",
    "    # Create sequences and labels\n",
    "    X, y = create_sequences(close_prices, seq_length)\n",
    "\n",
    "    # Split data into training (70%), validation (15%), and testing (15%)\n",
    "    train_size = int(len(X) * 0.7)\n",
    "    val_size = int(len(X) * 0.15)\n",
    "\n",
    "    X_train, X_val, X_test = X[:train_size], X[train_size:train_size + val_size], X[train_size + val_size:]\n",
    "    y_train, y_val, y_test = y[:train_size], y[train_size:train_size + val_size], y[train_size + val_size:]\n",
    "\n",
    "    # Reshape X for LSTM: (samples, time steps, features)\n",
    "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "    X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], 1))\n",
    "    X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "# Prepare the training, validation, and testing datasets\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = prepare_train_val_test(combined_data)\n",
    "\n",
    "print(f'X_train shape: {X_train.shape}, y_train shape: {y_train.shape}')\n",
    "print(f'X_val shape: {X_val.shape}, y_val shape: {y_val.shape}')\n",
    "print(f'X_test shape: {X_test.shape}, y_test shape: {y_test.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gnniv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_10\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_10\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_14 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │        \u001b[38;5;34m10,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_28 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m51\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,451</span> (40.82 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,451\u001b[0m (40.82 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,451</span> (40.82 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,451\u001b[0m (40.82 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# model implementation\n",
    "# LSTM Implementation:\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# LSTM Model with 30 time steps\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# Number of time steps and features\n",
    "n_steps = 30  # Using 30 days of past data\n",
    "n_features = 1  # Using only the 'Close_Scaled' column\n",
    "\n",
    "# Convert data to supervised format\n",
    "X, y = [], []\n",
    "for i in range(len(data) - n_steps):\n",
    "    X.append(combined_data['Close_Scaled'].iloc[i:i + n_steps].values)\n",
    "    y.append(combined_data['Close_Scaled'].iloc[i + n_steps])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Reshaping X to be 3-dimensional [samples, timesteps, features]\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "\n",
    "# LSTM Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "lstm_model = Sequential([\n",
    "    LSTM(50, activation='relu', input_shape=(n_steps, n_features)),\n",
    "    Dense(1)\n",
    "])\n",
    "lstm_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Model Summary\n",
    "print(lstm_model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,950</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │         \u001b[38;5;34m7,950\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m51\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,001</span> (31.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,001\u001b[0m (31.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,001</span> (31.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,001\u001b[0m (31.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# GRU Implementation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense\n",
    "\n",
    "# GRU Model\n",
    "gru_model = Sequential([\n",
    "    GRU(50, activation='relu', input_shape=(n_steps, n_features)),\n",
    "    Dense(1)\n",
    "])\n",
    "gru_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Model Summary\n",
    "print(gru_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gnniv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">23,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_12 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │        \u001b[38;5;34m23,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m51\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,307</span> (91.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,307\u001b[0m (91.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,307</span> (91.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m23,307\u001b[0m (91.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# CNN-LSTM\tImplementation:\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Flatten\n",
    "\n",
    "# CNN-LSTM Model\n",
    "cnn_lstm_model = Sequential([\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_steps, n_features)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    LSTM(50, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "cnn_lstm_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Model Summary\n",
    "print(cnn_lstm_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_13\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_13\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_13      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,585</span> │ input_layer_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ input_layer_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ multi_head_atten… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_13      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │      \u001b[38;5;34m3,585\u001b[0m │ input_layer_13[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ input_layer_13[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │          \u001b[38;5;34m2\u001b[0m │ multi_head_atten… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,587</span> (14.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,587\u001b[0m (14.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,587</span> (14.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,587\u001b[0m (14.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# transformer implementation\n",
    "from tensorflow.keras.layers import MultiHeadAttention, Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "input_layer = Input(shape=(n_steps, n_features))\n",
    "attention_output = MultiHeadAttention(num_heads=8, key_dim=64)(input_layer, input_layer)\n",
    "dense_output = Dense(1)(attention_output)\n",
    "transformer_model = Model(inputs=input_layer, outputs=dense_output)\n",
    "transformer_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Model Summary\n",
    "print(transformer_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">22,450</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │           \u001b[38;5;34m192\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m448\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │        \u001b[38;5;34m22,450\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m51\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,461</span> (122.89 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m31,461\u001b[0m (122.89 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,205</span> (121.89 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m31,205\u001b[0m (121.89 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> (1.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m256\u001b[0m (1.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# TCN (Temporal Convolutional Network) Implementation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Dense, Flatten, BatchNormalization, Activation\n",
    "\n",
    "# TCN Model\n",
    "tcn_model = Sequential([\n",
    "    Conv1D(filters=64, kernel_size=2, dilation_rate=1, activation='relu', input_shape=(n_steps, n_features)),\n",
    "    BatchNormalization(),\n",
    "    Conv1D(filters=64, kernel_size=2, dilation_rate=2, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Flatten(),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "tcn_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "\n",
    "# Model Summary\n",
    "print(tcn_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_15\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_15\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_15      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">10,400</span> │ input_layer_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">103,986</span> │ lstm_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ lstm_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │ multi_head_atten… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_15      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_13 (\u001b[38;5;33mLSTM\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m50\u001b[0m)    │     \u001b[38;5;34m10,400\u001b[0m │ input_layer_15[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m50\u001b[0m)    │    \u001b[38;5;34m103,986\u001b[0m │ lstm_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ lstm_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_27 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │         \u001b[38;5;34m51\u001b[0m │ multi_head_atten… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">114,437</span> (447.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m114,437\u001b[0m (447.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">114,437</span> (447.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m114,437\u001b[0m (447.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# LSTM-Transformer Hybrid Implementation\n",
    "from tensorflow.keras.layers import LSTM, MultiHeadAttention, Dense\n",
    "\n",
    "input_layer = Input(shape=(n_steps, n_features))\n",
    "lstm_output = LSTM(50, return_sequences=True)(input_layer)\n",
    "transformer_output = MultiHeadAttention(num_heads=8, key_dim=64)(lstm_output, lstm_output)\n",
    "dense_output = Dense(1)(transformer_output)\n",
    "lstm_transformer_model = Model(inputs=input_layer, outputs=dense_output)\n",
    "lstm_transformer_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Model Summary\n",
    "print(lstm_transformer_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0449 - val_loss: 0.0373\n",
      "Epoch 2/50\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0372 - val_loss: 0.0363\n",
      "Epoch 3/50\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0368 - val_loss: 0.0372\n",
      "Epoch 4/50\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0375 - val_loss: 0.0366\n",
      "Epoch 5/50\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0370 - val_loss: 0.0360\n",
      "Epoch 6/50\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0360 - val_loss: 0.0359\n",
      "Epoch 7/50\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0359 - val_loss: 0.0374\n",
      "Epoch 8/50\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0358 - val_loss: 0.0365\n",
      "Epoch 9/50\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0357 - val_loss: 0.0360\n",
      "Epoch 10/50\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0360 - val_loss: 0.0369\n",
      "Epoch 11/50\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0363 - val_loss: 0.0365\n",
      "Epoch 12/50\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0359 - val_loss: 0.0360\n",
      "Epoch 13/50\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0362 - val_loss: 0.0366\n",
      "Epoch 14/50\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.0363 - val_loss: 0.0385\n",
      "Epoch 15/50\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.0359 - val_loss: 0.0361\n",
      "Epoch 16/50\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0359 - val_loss: 0.0370\n",
      "Epoch 17/50\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0354 - val_loss: 0.0356\n",
      "Epoch 18/50\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0363 - val_loss: 0.0377\n",
      "Epoch 19/50\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0357 - val_loss: 0.0399\n",
      "Epoch 20/50\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0360 - val_loss: 0.0363\n",
      "Epoch 21/50\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0364 - val_loss: 0.0360\n",
      "Epoch 22/50\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0357 - val_loss: 0.0389\n",
      "Epoch 23/50\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0354 - val_loss: 0.0361\n",
      "Epoch 24/50\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0349 - val_loss: 0.0353\n",
      "Epoch 25/50\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0350 - val_loss: 0.0376\n",
      "Epoch 26/50\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0356 - val_loss: 0.0392\n",
      "Epoch 27/50\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0354 - val_loss: 0.0357\n",
      "Epoch 28/50\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0357 - val_loss: 0.0373\n",
      "Epoch 29/50\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0352 - val_loss: 0.0422\n",
      "Epoch 30/50\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0347 - val_loss: 0.0371\n",
      "Epoch 31/50\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.0348 - val_loss: 0.0380\n",
      "Epoch 32/50\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.0350 - val_loss: 0.0365\n",
      "Epoch 33/50\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.0350 - val_loss: 0.0361\n",
      "Epoch 34/50\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.0354 - val_loss: 0.0382\n",
      "Epoch 35/50\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0353 - val_loss: 0.0370\n",
      "Epoch 36/50\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0348 - val_loss: 0.0366\n",
      "Epoch 37/50\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0356 - val_loss: 0.0373\n",
      "Epoch 38/50\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0352 - val_loss: 0.0376\n",
      "Epoch 39/50\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0351 - val_loss: 0.0368\n",
      "Epoch 40/50\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0348 - val_loss: 0.0363\n",
      "Epoch 41/50\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0346 - val_loss: 0.0364\n",
      "Epoch 42/50\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0353 - val_loss: 0.0388\n",
      "Epoch 43/50\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0358 - val_loss: 0.0366\n",
      "Epoch 44/50\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0353 - val_loss: 0.0363\n",
      "Epoch 45/50\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0348 - val_loss: 0.0366\n",
      "Epoch 46/50\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0351 - val_loss: 0.0364\n",
      "Epoch 47/50\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0346 - val_loss: 0.0366\n",
      "Epoch 48/50\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0347 - val_loss: 0.0376\n",
      "Epoch 49/50\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0346 - val_loss: 0.0391\n",
      "Epoch 50/50\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0347 - val_loss: 0.0365\n"
     ]
    }
   ],
   "source": [
    "# Train each model\n",
    "history = lstm_model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "LSTM MAE: 0.5478087971573166\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "GRU MAE: 0.49672214337428844\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "CNN-LSTM MAE: 0.5343429321469575\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "Error predicting with model Transformer: Found input variables with inconsistent numbers of samples: [3147, 31470]\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "TCN MAE: 0.6316606184925599\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "Error predicting with model LSTM-Transformer: Found input variables with inconsistent numbers of samples: [3147, 31470]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluation metrics\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define your models in a dictionary for easier iteration (assuming they are already trained)\n",
    "models = {\n",
    "    'LSTM': lstm_model,\n",
    "    'GRU': gru_model,\n",
    "    'CNN-LSTM': cnn_lstm_model,\n",
    "    'Transformer': transformer_model,\n",
    "    'TCN': tcn_model,\n",
    "    'LSTM-Transformer': lstm_transformer_model\n",
    "}\n",
    "\n",
    "mae_scores = []\n",
    "successful_models = []\n",
    "\n",
    "# Generate predictions and calculate MAE for each model\n",
    "for model_name, model in models.items():\n",
    "    try:\n",
    "        # Check the expected input shape of the model\n",
    "        input_shape = model.input_shape\n",
    "        \n",
    "        # Adjust X_test based on the model's input shape\n",
    "        if input_shape[1] == 10:  # Models that expect 10 time steps\n",
    "            X_test_reshaped = X_test[:, :10, :]\n",
    "        elif input_shape[1] == 30:  # Models that expect 30 time steps\n",
    "            X_test_reshaped = X_test\n",
    "        else:\n",
    "            print(f\"Warning: Unexpected input shape for model {model_name}: {input_shape}\")\n",
    "            continue\n",
    "\n",
    "        # Predict using the reshaped input\n",
    "        y_pred = model.predict(X_test_reshaped)\n",
    "\n",
    "        # Reshape y_pred if necessary\n",
    "        if y_pred.shape != y_test.shape:\n",
    "            y_pred = y_pred.reshape(-1)\n",
    "\n",
    "        # Calculate MAE\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        mae_scores.append(mae)\n",
    "        successful_models.append(model_name)  # Track successful model names\n",
    "        print(f'{model_name} MAE: {mae}')\n",
    "    except Exception as e:\n",
    "        print(f\"Error predicting with model {model_name}: {e}\")\n",
    "\n",
    "# Plot the MAE comparison\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(successful_models, mae_scores)  # Use successful model names only\n",
    "plt.title('Model Comparison - MAE')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('MAE')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Selection and Implementation\n",
    "# Model Choices:\n",
    "# LSTM: Captures long-term temporal dependencies.\n",
    "# Transformer: Efficient for long-range patterns.\n",
    "# TCN (Temporal Convolutional Network): Fast training for long sequences.\n",
    "# CNN-LSTM: Combines spatial and temporal feature extraction.\n",
    "# LSTM-Transformer Hybrid: Combines temporal memory with attention mechanisms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization, Bidirectional, MultiHeadAttention, LayerNormalization, Input, Add\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from tensorflow.keras.optimizers import Adam, AdamW\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import optuna\n",
    "\n",
    "# Custom Learning Rate Scheduler\n",
    "def lr_scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * float(tf.math.exp(-0.05))\n",
    "       \n",
    "\n",
    "# Enhanced LSTM Model\n",
    "def create_lstm_model(input_shape, units=64, dropout_rate=0.2):\n",
    "    model = Sequential([\n",
    "        Bidirectional(LSTM(units, activation='relu', return_sequences=True, input_shape=input_shape)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout_rate),\n",
    "        LSTM(units, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(1, activation='linear')\n",
    "    ])\n",
    "    model.compile(optimizer=AdamW(learning_rate=0.001), loss='mse')\n",
    "    return model\n",
    "\n",
    "# Enhanced Transformer Model\n",
    "def create_transformer_model(input_shape, num_heads=8, key_dim=64, dropout_rate=0.2):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    attention = MultiHeadAttention(num_heads=num_heads, key_dim=key_dim)(inputs, inputs)\n",
    "    attention = Dropout(dropout_rate)(attention)\n",
    "    attention = Add()([inputs, attention])\n",
    "    attention = LayerNormalization()(attention)\n",
    "\n",
    "    # Feed Forward Network\n",
    "    ff = Dense(128, activation='relu')(attention)\n",
    "    ff = Dropout(dropout_rate)(ff)\n",
    "    ff = Dense(64, activation='relu')(ff)\n",
    "    ff = Add()([attention, ff])\n",
    "    outputs = Dense(1, activation='linear')(ff)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer=AdamW(learning_rate=0.001), loss='mse')\n",
    "    return model\n",
    "\n",
    "# Model Evaluation Function\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    return rmse, mae\n",
    "\n",
    "# Optuna Hyperparameter Tuning\n",
    "def objective(trial):\n",
    "    units = trial.suggest_int('units', 32, 128)\n",
    "    # lr = trial.suggest_loguniform('lr', 1e-5, 1e-2)\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-2, log=True)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
    "    num_heads = trial.suggest_int('num_heads', 4, 12)\n",
    "    key_dim = trial.suggest_int('key_dim', 32, 128)\n",
    "\n",
    "    model_choice = trial.suggest_categorical('model', ['lstm', 'transformer'])\n",
    "    if model_choice == 'lstm':\n",
    "        model = create_lstm_model((30, 1), units, dropout_rate)\n",
    "    else:\n",
    "        model = create_transformer_model((30, 1), num_heads, key_dim, dropout_rate)\n",
    "\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    lr_scheduler_callback = LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "    model.fit(X_train, y_train, \n",
    "              epochs=50, \n",
    "              batch_size=batch_size, \n",
    "              validation_data=(X_val, y_val), \n",
    "              verbose=0, \n",
    "              callbacks=[early_stop, lr_scheduler_callback])\n",
    "    loss = model.evaluate(X_val, y_val, verbose=0)\n",
    "    return loss\n",
    "\n",
    "# Optimize using Optuna\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "print(f\"Best Parameters: {study.best_params}\")\n",
    "\n",
    "# Train and Evaluate the Best Model\n",
    "best_params = study.best_params\n",
    "if best_params['model'] == 'lstm':\n",
    "    model = create_lstm_model((30, 1), best_params['units'], best_params['dropout_rate'])\n",
    "else:\n",
    "    model = create_transformer_model((30, 1), best_params['num_heads'], best_params['key_dim'], best_params['dropout_rate'])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "# lr_scheduler_callback = LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                   epochs=50, \n",
    "                   # batch_size=best_params['batch_size'], \n",
    "                   validation_data=(X_val, y_val), \n",
    "                   callbacks=[early_stop, lr_scheduler_callback])\n",
    "\n",
    "# Evaluate on Test Data\n",
    "rmse, mae = evaluate_model(model, X_test, y_test)\n",
    "print(f'Best Model RMSE: {rmse}, MAE: {mae}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
